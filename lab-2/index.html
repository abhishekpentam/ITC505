<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Elsevier OA CC-BY Corpus - HTML Conversion</title>
</head>
<body>
    <!-- Main Research Paper -->
    <article>
        <h1>Elsevier OA CC-BY Corpus</h1>
        <p><strong>Authors:</strong> Daniel Kershaw (Elsevier Ltd, London, UK) | Rob Koeling (Elsevier Ltd, London, UK)</p>
        <p><strong>Date:</strong> September 16, 2020</p>

        <h2>Abstract</h2>
        <p>
            We introduce the Elsevier OA CC-BY corpus. This is the first open corpus of scientific research papers 
            which has a representative sample from across scientific disciplines. This corpus not only includes 
            the full text of the article, but also the metadata of the documents, along with the bibliographic 
            information for each reference.
        </p>

        <h2>1. Introduction</h2>
        <p>
            We are pleased to release the Elsevier OA CC-BY corpus for NLP and AI research. This is a corpus of 
            40,091 open access articles from across Elsevier’s journals representing a large scale, cross-discipline 
            set of research data to support NLP and ML research. Research into the application of NLP and ML to 
            scholarly content has attracted considerable attention in recent years. However, progress has been 
            limited due to a lack of large, cross-discipline datasets. This dataset addresses that gap.
        </p>

        <h2>2. Related Work</h2>
        <p>
            Open source datasets of academic articles are not new, with notable corpora including PubMed OA, 
            CiteSeerX, ACL Anthology, and arXiv. However, these often lack resolved metadata, making it difficult 
            to establish citation connections. Projects such as Semantic Scholar’s Literature Graph and S2ORC have 
            advanced this area by extracting references and building large-scale literature graphs.
        </p>

        <h2>3. Dataset</h2>
        <h3>3.1 Data Sampling</h3>
        <p>
            The corpus consists of articles published since 2014, covered by a CC-BY 4.0 licence. A stratified sampling 
            method ensured equal representation from Elsevier’s subject classifications (ASJC codes). 2,000 documents 
            were sampled from each of 27 top-level disciplines.
        </p>

        <h3>3.2 Data Structure</h3>
        <p>
            Each article is contained within its own JSON file, with metadata (authors, title, publication info), 
            abstract, body text split by sentences, and bibliographic references. The structure allows reconstruction 
            of article hierarchy and linkage between references.
        </p>

        <h3>3.3 Data Coverage and Statistics</h3>
        <p>
            The dataset has nearly full coverage of metadata, abstracts, and references. Publication years range from 
            2014–2020, with over 40,000 documents across multiple disciplines including medicine, engineering, 
            environmental science, computer science, and more.
        </p>

        <h2>4. Use of Dataset</h2>
        <p>
            The dataset can be downloaded from <a href="https://data.mendeley.com/datasets/zm33cdndxs/3" target="_blank">
            Mendeley Data</a>. It supports ML and NLP research across domains and can be used to build task-specific 
            datasets for citation intent classification, entity extraction, and more.
        </p>

        <h2>5. Conclusion and Future Work</h2>
        <p>
            This dataset provides a large-scale, cross-discipline corpus that supports the development of ML and NLP 
            models targeting scholarly text. It complements existing domain-specific corpora and enables validation 
            across disciplines.
        </p>

        <h2>6. Acknowledgements</h2>
        <p>
            The authors thank colleagues at Elsevier, including Darin McBeath, Anita Dewaard, and Noelle Gracy, 
            for their contributions.
        </p>

        <h2>References</h2>
        <ol>
            <li>C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing system. ACM DL ’98, 1998.</li>
            <li>Dragomir R. Radev, Pradeep Muthukrishnan, and Vahed Qazvinian. The ACL Anthology Network Corpus. NLPIR4DL, 2009.</li>
            <li>Tarek Saier and Michael Färber. unarXive: A large scholarly dataset with full-text and metadata. Scientometrics, 2020.</li>
            <li>Waleed Ammar et al. Construction of the Literature Graph in Semantic Scholar. NAACL-HLT Industry Papers, 2018.</li>
            <li>Kyle Lo et al. S2ORC: The Semantic Scholar Open Research Corpus. ACL 2020.</li>
            <li>Lucy Lu Wang et al. CORD-19: The COVID-19 Open Research Dataset, 2020.</li>
            <li>Additional references as cited in the paper...</li>
        </ol>
    </article>

    <!-- Addendum -->
    <article>
        <h2>Addendum</h2>
        <p>
            In converting this paper to HTML, I structured the document using semantic HTML5 elements. The title of 
            the paper is placed inside an <code>&lt;h1&gt;</code>, while major sections such as Abstract, Introduction, and 
            Dataset use <code>&lt;h2&gt;</code>. Subsections within the dataset section use <code>&lt;h3&gt;</code>. Paragraphs 
            are wrapped in <code>&lt;p&gt;</code> tags for readability.
        </p>
        <p>
            I used an ordered list <code>&lt;ol&gt;</code> for references, as scholarly works require numbered citations. 
            Hyperlinks (e.g., to Mendeley Data) were added using <code>&lt;a&gt;</code> tags. Two <code>&lt;article&gt;</code> 
            elements separate the research paper and the addendum, making the structure clearer for graders.
        </p>
        <p>
            The footer script provided in the assignment is included so that the page automatically displays the last 
            modification date. This ensures compliance with the submission requirements.
        </p>
    </article>

    <!-- Footer with last modified script -->
    <footer>
        <p>Last updated: <span id="lastModified"></span></p>
    </footer>
    <script type="text/javascript">
        var x = document.lastModified;
        document.getElementById('lastModified').textContent = x;
    </script>
</body>
</html>
